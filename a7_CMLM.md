压缩混合线性模型（Compressed Mixed Linear Model, CMLM）是在混合线性模型（MLM）基础上的一种改进，用于提高GWAS分析的效率和精度。CMLM的核心思想是通过**样本聚类**减少模型中个体的数量，从而压缩随机效应矩阵的规模。这种压缩过程不仅减少了计算量，也提高了对多态性SNP的检测效率。

下面我们详细分析CMLM的数学原理和求解过程。

---

### **1. 压缩混合线性模型的基本结构**

CMLM的数学表达式和传统的混合线性模型类似，可以表示为：

$$
Y = X\beta + Z_c u_c + \epsilon
$$

其中：
- $ Y $ 是 $ n \times 1 $ 的表型向量，表示 $ n $ 个个体的表型值。
- $ X $ 是 $ n \times p $ 的设计矩阵，包含固定效应的自变量（包括SNP基因型和协变量，如性别、年龄等）。
- $ \beta $ 是 $ p \times 1 $ 的固定效应系数向量，表示SNP基因型对表型的固定效应。
- $ Z_c $ 是 $ n \times q $ 的压缩设计矩阵，表示压缩后的随机效应矩阵。
- $ u_c $ 是 $ q \times 1 $ 的随机效应向量，假设 $ u_c \sim N(0, \sigma_u^2 I_q) $，其中 $ I_q $ 是 $ q \times q $ 的单位矩阵。
- $ \epsilon $ 是 $ n \times 1 $ 的误差项向量，假设 $ \epsilon \sim N(0, \sigma_\epsilon^2 I_n) $。

在CMLM中，随机效应被压缩成聚类组的效应，而非每个个体的效应。这种压缩显著减少了模型中的参数数量，使得计算变得更高效。

---

### **2. 压缩的原理：样本聚类**

在传统的MLM中，随机效应矩阵 $ Z $ 直接作用于每个个体，导致方差矩阵的维度随着样本数量 $ n $ 增加，计算复杂度很高。CMLM通过将样本聚类来减少随机效应的维度，步骤如下：

1. **样本聚类**：基于亲缘关系矩阵 $ K $ 或其他方法，将 $ n $ 个个体聚类成 $ q $ 个群组。每个群组代表一些遗传相似性较高的个体。
   
2. **构建压缩矩阵** $ Z_c $：将原设计矩阵 $ Z $ 压缩成新的设计矩阵 $ Z_c $，其中 $ Z_c $ 的维度为 $ n \times q $。$ Z_c $ 表示每个个体在聚类后所属的群组。

3. **群组的随机效应**：每个群组的随机效应表示一组遗传相似个体的影响，这样每个群组只需要一个随机效应参数 $ u_c $。

通过这种聚类，CMLM有效减少了计算量，特别是在大样本研究中，这种压缩显著提高了计算效率。

---

### **3. CMLM的协方差结构**

在CMLM中，表型 $ Y $ 的协方差矩阵可以表示为：

$$
V = \sigma_u^2 Z_c Z_c^T + \sigma_\epsilon^2 I_n
$$

其中：

- $ \sigma_u^2 Z_c Z_c^T $ 是压缩后的随机效应协方差矩阵，反映了群组间的遗传相似性带来的变异。
- $ \sigma_\epsilon^2 I_n $ 是误差项的协方差矩阵。

### **4. 参数估计的过程**

由于CMLM仍然是混合线性模型的一种，我们可以使用**最大似然估计（Maximum Likelihood, ML）** 或 **限制最大似然估计（Restricted Maximum Likelihood, REML）** 来估计参数。过程如下：

#### (1) 对数似然函数

对数似然函数可以写为：

$$
\ell(\beta, \sigma_u^2, \sigma_\epsilon^2 | Y) = -\frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln |V| - \frac{1}{2} (Y - X\beta)^T V^{-1} (Y - X\beta)
$$

#### (2) 固定效应 $ \beta $ 的估计

类似于传统的GLM估计，固定效应的最优估计为：

$$
\hat{\beta} = (X^T V^{-1} X)^{-1} X^T V^{-1} Y
$$

#### (3) 随机效应的方差 $ \sigma_u^2 $ 和误差方差 $ \sigma_\epsilon^2 $ 的估计

对于方差分量的估计，通常使用REML方法来最大化似然函数，从而估计 $ \sigma_u^2 $ 和 $ \sigma_\epsilon^2 $。在CMLM中，REML的计算步骤与MLM类似，只是维度被压缩，因此具体的计算公式与传统MLM一致，但计算效率更高。

---

### **5. CMLM求解的数值优化**

在实际中，CMLM的优化常用**EM算法**或**牛顿-拉夫森法**来迭代估计方差参数 $ \sigma_u^2 $ 和 $ \sigma_\epsilon^2 $。这里简要介绍基于EM算法的求解过程：

#### **E步**（期望步）

根据当前参数估计值，计算压缩随机效应 $ u_c $ 的条件期望和协方差。

1. 随机效应 $ u_c $ 的条件期望：

$$
\mathbb{E}(u_c | Y) = \sigma_u^2 Z_c^T V^{-1} (Y - X\beta)
$$

2. 随机效应的条件协方差：

$$
\text{Cov}(u_c | Y) = \sigma_u^2 I_q - \sigma_u^2 Z_c^T V^{-1} Z_c \sigma_u^2
$$

#### **M步**（最大化步）

在M步中，更新参数 $ \beta $、$ \sigma_u^2 $ 和 $ \sigma_\epsilon^2 $。

1. **更新固定效应** $ \beta $：

$$
\hat{\beta} = (X^T V^{-1} X)^{-1} X^T V^{-1} Y
$$

2. **更新随机效应方差** $ \sigma_u^2 $：

$$
\sigma_u^{2(t+1)} = \frac{1}{q} \left( \mathbb{E}(u_c^T u_c | Y) + \text{tr}\left( \text{Cov}(u_c | Y) \right) \right)
$$

3. **更新误差方差** $ \sigma_\epsilon^2 $：

$$
\sigma_\epsilon^{2(t+1)} = \frac{1}{n} \left( \| Y - X\hat{\beta} - Z_c \mathbb{E}(u_c | Y) \|^2 + \text{tr}\left( Z_c \text{Cov}(u_c | Y) Z_c^T \right) \right)
$$

---

### **6. CMLM的优点与局限性**

- **优点**：CMLM通过对样本聚类并构建压缩的随机效应矩阵 $ Z_c $，显著降低了模型的计算复杂度，尤其适用于大规模GWAS数据。
- **局限性**：由于CMLM基于样本聚类，聚类的质量会直接影响模型的准确性。如果聚类不合理，可能会导致一些真实的SNP-表型关联被忽略。

---

### **总结**

CMLM在MLM的基础上，通过对个体进行聚类来压缩随机效应矩阵，从而提高计算效率。通过EM算法或其他数值优化方法，CMLM能够有效地估计模型参数，并提供对群体结构校正后的SNP-表型关联分析。这种方法在大规模数据上表现尤为优异，是处理高维度、复杂表型数据的一种有效工具。\\[\\]\\(\\)