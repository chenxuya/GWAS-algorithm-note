[iCircRBP-DHN: identification of circRNA-RBP interaction sites using deep hierarchical network](https://academic.oup.com/bib/article/22/4/bbaa274/5943796?login=true)
以下是关于文章《iCircRBP-DHN：利用深度层次网络识别circRNA-RBP相互作用位点》的详细解读，包括模型架构、数据输入输出、数据预处理及生物学意义：

## iCircRBP-DHN：基于深度层次网络的circRNA-RBP相互作用位点识别

### 1. 背景与研究目的
- 环状RNA（circRNA）广泛存在于真核生物中，通过独特的“头尾连接”剪接形成。由于其闭合环状结构，circRNA在细胞中比线性RNA更稳定，并且在特定组织或发育阶段中具有特定表达模式。
- circRNA不仅在基因表达调控中起重要作用，还在癌症等疾病诊断中表现为生物标志物。许多circRNA的功能依赖于与RNA结合蛋白（RBP）的相互作用，因此识别circRNA-RBP相互作用位点至关重要。
- 本文提出了iCircRBP-DHN模型，通过深度层次网络（Deep Hierarchical Network，DHN）自动提取序列特征，从而识别circRNA上的RBP结合位点。该模型利用新型特征编码方法CircRNA2Vec和K-元核苷酸频率模式（KNFP），能够捕捉序列的局部和全局上下文信息。

---

### 2. 数据预处理与输入数据结构
- **数据来源**：circRNA序列来源于circRNA交互组数据库（circRNA interactome database），从37个circRNA数据集中获得32216个circRNA样本，每个样本包含101个核苷酸的片段。
- **数据预处理**：
  - **正样本**：通过实验验证的circRNA-RBP相互作用位点，包含结合位点两侧各50个核苷酸的序列片段。
  - **负样本**：从其他circRNA片段中随机采样，保证样本长度一致。
  - **特征编码**：
    - **K-元核苷酸频率模式（KNFP）**：用于捕捉局部上下文信息，提取单核苷酸、二核苷酸和三核苷酸的组成频率，生成的特征向量涵盖4$^K$维。
    - **CircRNA2Vec**：通过Doc2Vec算法生成词向量，捕捉circRNA的长程依赖信息。每个序列被切分为10个核苷酸的重叠子序列，以生成连续的分布式表示，用于表征全局上下文特征。

---

### 3. 模型架构

#### 深度多尺度残差网络（DMSRN）
- **功能**：负责提取输入特征的局部上下文信息。
- **架构**：
  - 输入特征先分别通过不同卷积滤波器处理，以平衡特征分布。
  - 多尺度卷积核（1、3、5窗口大小）捕获不同范围的依赖信息，卷积层之间通过残差连接（skip connections）增加信息流通性，避免梯度消失。
  - 卷积层输出经过批归一化（BN）和Swish激活函数处理，以增强模型的训练效率和稳定性。

#### 双向门控循环单元网络（BiGRU）及自注意力机制
- **功能**：提取序列的全局上下文信息。
- **架构**：
  - 在DMSRN输出的基础上，利用双向GRU（BiGRU）来捕捉序列中长程依赖关系，从而获取从序列前后传递的上下文信息。
  - 自注意力机制用于加权计算序列中的重要位置，使模型更关注具有显著信息的位点，有效地提升了circRNA-RBP相互作用位点的识别效果。

#### 全连接层及输出
- BiGRU和自注意力机制的输出通过扁平化处理，进入全连接层，并通过Softmax分类器进行最终的circRNA-RBP相互作用位点的预测。

---

### 4. 数据的输入输出及生物学意义
- **输入数据**：每个输入样本为101个核苷酸长度的circRNA片段，包含KNFP生成的局部上下文特征向量和CircRNA2Vec生成的全局特征向量。
- **输出数据**：分类器输出两个标签，分别代表RBP结合位点（正样本）和非结合位点（负样本）的概率。
- **生物学意义**：
  - KNFP特征向量捕捉了局部的核苷酸模式，这些模式可能是RBP结合的识别位点。
  - CircRNA2Vec特征向量描述了circRNA的长程依赖结构，由于circRNA的闭合环结构，该特征反映了序列中不同位置之间的相互关系，有助于识别特定的结合位点。
  - DMSRN和BiGRU分别从局部和全局层面提取circRNA的特征信息，能够有效捕捉circRNA与RBP之间的相互作用规律。

---

### 5. 模型的训练与评估
- **训练过程**：数据集划分为80%训练集和20%测试集，模型使用Adam优化器进行训练，使用早停策略避免过拟合。
- **损失函数**：模型采用交叉熵损失函数来优化分类精度，使用AUC（曲线下面积）等指标评估模型性能。
- **评估结果**：iCircRBP-DHN在37个circRNA数据集上的AUC显著优于其他方法，特别是在包含长程依赖的circRNA数据集上表现出色。通过实验表明，KNFP和CircRNA2Vec特征编码方案在捕捉RBP结合位点方面具有优越性。

---

### 6. 总结
- iCircRBP-DHN模型通过深度学习自动提取circRNA的多层次特征，显著提升了circRNA-RBP相互作用位点识别的准确性。
- 该模型在包含长程依赖的circRNA数据上表现出色，证明其适用于大规模基因组数据的分析，为circRNA功能研究提供了新工具。
- KNFP和CircRNA2Vec作为特征编码方案展示出在捕捉局部和全局信息的能力，有助于进一步深入理解circRNA的调控机制及其与RBP的相互作用。

# KNFP模块具体是如何工作的
KNFP模块（K-元核苷酸频率模式）通过提取RNA序列中的局部特征模式，为iCircRBP-DHN模型提供序列的局部上下文信息。KNFP的主要任务是计算RNA序列中的单核苷酸、二核苷酸和三核苷酸的出现频率，形成特征向量，用于识别特定的核苷酸组合与RNA结合蛋白（RBP）结合位点的关联性。以下是KNFP模块的工作原理和计算方法：

### 1. 特征表示
KNFP模块通过不同K值计算序列中各个核苷酸组合的出现频率。给定RNA序列$ S = s_1 s_2 \dots s_n $，其中每个 $ s_i $ 表示序列中的一个核苷酸，核苷酸字母表为 $\{A, C, G, U\}$。

#### K-元核苷酸频率计算
KNFP通常计算单核苷酸、二核苷酸和三核苷酸的频率，具体为：
1. **单核苷酸频率（K=1）**：统计每个核苷酸 $ A, C, G, U $ 在序列中的频率。
2. **二核苷酸频率（K=2）**：统计每对相邻核苷酸的组合在序列中的出现频率，如 $ AA, AC, \dots, UU $。
3. **三核苷酸频率（K=3）**：统计每三个相邻核苷酸的组合在序列中的出现频率，如 $ AAA, AAC, \dots, UUU $。

对于任意的 $ K $-元组合（称为K-gram），其频率计算公式为：

$$
f_{K}(w) = \frac{\text{count}(w)}{n - K + 1}
$$

其中：
- $ f_{K}(w) $ 表示K-gram $ w $ 的频率。
- $ \text{count}(w) $ 表示K-gram $ w $ 在序列中出现的次数。
- $ n $ 表示RNA序列的长度。
- $ K $ 表示K-gram的长度。

### 2. 特征向量表示
对于给定的K值，KNFP会生成一个 $ 4^K $ 维的特征向量。例如：
- K=1 时，特征向量维度为 4（$A, C, G, U$）。
- K=2 时，特征向量维度为 16（$AA, AC, \dots, UU$）。
- K=3 时，特征向量维度为 64（$AAA, AAC, \dots, UUU$）。

最后，将不同K值的特征向量拼接在一起，形成包含所有K-gram频率信息的高维特征向量。这一特征向量可以表示为：

$$
\mathbf{F} = [f_1(A), f_1(C), f_1(G), f_1(U), \dots, f_2(AA), f_2(AC), \dots, f_3(UUU)]
$$

其中，$\mathbf{F}$ 是包含不同K-gram频率的特征向量。

### 3. 生物学意义
KNFP模块计算的K-gram频率能够捕捉RNA序列中的局部核苷酸模式，这些模式可能代表RBP的结合位点。特定的核苷酸组合和频率分布反映了RBP的偏好性，这有助于模型识别特定的结合位点模式并预测RBP的结合区域。

KNFP生成的特征向量被用于模型的深层次网络中，与序列的其他特征（如全局上下文）结合，以提高模型的预测能力。

# 解析CircRNA2Vec 模块的工作原理
CircRNA2Vec模块是iCircRBP-DHN模型中用于捕捉circRNA序列的全局上下文特征的关键模块。它采用类似于Doc2Vec的方式，将RNA序列分割成多个子序列，将每个子序列映射为向量，并最终形成一个能够表达circRNA全局特征的高维向量。以下是CircRNA2Vec模块的工作原理和数学表示。

### 1. 特征表示
CircRNA2Vec模块通过将circRNA序列表示为多个连续的短序列片段来提取全局上下文信息。给定一个长度为 $ n $ 的RNA序列 $ S = s_1 s_2 \dots s_n $，CircRNA2Vec会将 $ S $ 分割成一系列重叠的短片段（子序列）。

#### 子序列生成
假设每个子序列的长度为 $ l $，子序列之间的步长为 $ t $。则对于给定的 $ S $，可以生成子序列集合 $ \{ S_1, S_2, \dots, S_k \} $，其中每个 $ S_i $ 表示一个子序列。子序列生成的过程可以描述为：

$$
S_i = \{ s_{(i-1)t+1}, s_{(i-1)t+2}, \dots, s_{(i-1)t+l} \}
$$

其中：
- $ S_i $ 是第 $ i $ 个子序列。
- $ t $ 是步长，表示每个子序列之间的间隔。
- $ k = \left\lceil \frac{n - l}{t} + 1 \right\rceil $ 是生成的子序列数量。

### 2. 子序列向量化
CircRNA2Vec使用Word2Vec的Skip-gram方法对每个子序列进行向量化，生成一个分布式向量表示。

1. **Skip-gram模型**：Skip-gram是一种通过预测上下文词来学习目标词向量的方法。在CircRNA2Vec中，每个子序列被视为一个“词”，序列中的其他子序列视为上下文，Skip-gram通过最小化目标子序列和其上下文之间的距离来训练模型。
  
2. **训练目标**：在Skip-gram模型中，对于每个子序列 $ S_i $，我们希望最大化该子序列与其上下文子序列的共现概率。定义目标函数 $ J $ 如下：

$$
J = \sum_{i=1}^{k} \sum_{j \in \text{context}(i)} \log P(S_j | S_i)
$$

其中，$ P(S_j | S_i) $ 表示在给定子序列 $ S_i $ 的条件下，生成上下文子序列 $ S_j $ 的概率。

3. **条件概率**：Skip-gram模型中的条件概率 $ P(S_j | S_i) $ 通常使用softmax函数表示：

$$
P(S_j | S_i) = \frac{\exp(\mathbf{v}_{S_j} \cdot \mathbf{v}_{S_i})}{\sum_{w \in V} \exp(\mathbf{v}_w \cdot \mathbf{v}_{S_i})}
$$

其中：
- $ \mathbf{v}_{S_i} $ 和 $ \mathbf{v}_{S_j} $ 分别是子序列 $ S_i $ 和 $ S_j $ 的向量表示。
- $ V $ 是所有可能子序列的词汇表。
- $ \cdot $ 表示向量的点积操作。

通过最大化此目标函数，CircRNA2Vec模块能够为每个子序列生成一个向量，使得具有相似上下文的子序列在高维空间中接近。

### 3. 全局特征向量的生成
在完成子序列向量化后，将每个子序列的向量拼接或平均，以生成整个circRNA序列的全局特征向量。假设 $ \mathbf{v}_{S_i} $ 是第 $ i $ 个子序列的向量，则circRNA全局特征向量 $ \mathbf{V}_{\text{circRNA}} $ 可表示为：

$$
\mathbf{V}_{\text{circRNA}} = \frac{1}{k} \sum_{i=1}^{k} \mathbf{v}_{S_i}
$$

或者直接将每个 $ \mathbf{v}_{S_i} $ 拼接成一个更高维的向量：

$$
\mathbf{V}_{\text{circRNA}} = [\mathbf{v}_{S_1}, \mathbf{v}_{S_2}, \dots, \mathbf{v}_{S_k}]
$$

### 4. 生物学意义
CircRNA2Vec模块通过生成circRNA序列的分布式向量表示，能够有效捕捉序列中的长程依赖信息。这对于circRNA来说尤为重要，因为其环状结构使得序列不同位置之间存在潜在的全局相互关系。通过引入这种全局特征，CircRNA2Vec可以帮助模型识别那些可能受到远程调控或结构依赖的RNA结合蛋白（RBP）结合位点，从而提高识别准确性。

这种基于分布式表示的方法不仅提高了特征的表示能力，而且能够在深度学习模型中有效整合序列的上下文信息，为识别circRNA-RBP相互作用位点提供了关键支持。

# 解析文章中模型的主体模型
iCircRBP-DHN模型的主体模型包括两个主要部分：**深度多尺度残差网络（DMSRN）**和**双向门控循环单元网络（BiGRU）结合自注意力机制**。以下是模型的具体结构和数学表示。

---

### 1. 深度多尺度残差网络（DMSRN）

**DMSRN**的核心是通过多尺度卷积和残差连接来提取RNA序列的局部上下文特征。DMSRN的结构包括以下几部分：

#### 1.1 多尺度卷积层
- RNA序列的特征矩阵 $ X $ 经过多尺度卷积层处理，每个卷积核大小对应不同的窗口大小（如1、3、5窗口），从而捕捉不同的上下文依赖性。
- 给定输入特征矩阵 $ X \in \mathbb{R}^{L \times d} $，其中 $ L $ 是序列长度，$ d $ 是特征维度，每个卷积核的计算如下：

$$
H^{(k)} = \text{ReLU}(W^{(k)} * X + b^{(k)})
$$

其中：
- $ W^{(k)} $ 和 $ b^{(k)} $ 是第 $ k $ 个卷积核的权重和偏置。
- $ * $ 表示卷积操作。
- $ H^{(k)} $ 是第 $ k $ 个卷积核产生的输出特征图。

#### 1.2 多尺度特征拼接
将不同尺度的卷积输出特征图拼接在一起形成一个新的特征矩阵 $ H $：

$$
H = [H^{(1)}, H^{(3)}, H^{(5)}]
$$

其中，$ H \in \mathbb{R}^{L \times (d_1 + d_2 + d_3)} $ 是拼接后的特征矩阵，$ d_1, d_2, d_3 $ 分别为不同卷积核对应的输出维度。

#### 1.3 残差连接
为了避免梯度消失并增强信息传递，DMSRN通过残差连接（skip connection）将输入直接加到卷积层的输出上：

$$
Z = H + X
$$

其中，$ Z $ 是DMSRN的输出矩阵，将包含序列的多尺度局部上下文信息。

---

### 2. 双向门控循环单元网络（BiGRU）与自注意力机制

**BiGRU和自注意力机制**负责从DMSRN的输出特征中提取全局上下文信息。BiGRU用于捕捉序列的长程依赖性，而自注意力机制用于强调序列中的重要位点。

#### 2.1 双向门控循环单元网络（BiGRU）
BiGRU是一种循环神经网络（RNN）结构，通过两个方向的GRU层捕获RNA序列的前向和后向依赖信息。给定DMSRN输出的特征矩阵 $ Z $，BiGRU的输出 $ H_{\text{BiGRU}} $ 可以表示为：

$$
H_{\text{BiGRU}} = \text{BiGRU}(Z)
$$

其中，$ H_{\text{BiGRU}} \in \mathbb{R}^{L \times 2h} $，$ h $ 是GRU隐藏层的单向维度，$ 2h $ 表示双向GRU的输出维度。

#### 2.2 自注意力机制
自注意力机制用于加权不同位置的特征，使模型能够更加关注在circRNA-RBP相互作用中关键的位点。对于BiGRU的输出 $ H_{\text{BiGRU}} $，自注意力机制的计算过程如下：

1. **计算注意力得分**：
   生成注意力得分 $ \alpha_i $，衡量每个位置的重要性：

   $$
   e_i = \tanh(W_a H_{\text{BiGRU}}[i] + b_a)
   $$

   其中：
   - $ W_a $ 和 $ b_a $ 是可学习的权重和偏置。
   - $ H_{\text{BiGRU}}[i] $ 表示BiGRU输出的第 $ i $ 个位置的向量。

2. **归一化注意力得分**：
   使用softmax函数将注意力得分归一化：

   $$
   \alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^{L} \exp(e_j)}
   $$

3. **生成注意力加权的特征向量**：
   将注意力权重应用于BiGRU的输出，生成最终的全局上下文表示 $ V $：

   $$
   V = \sum_{i=1}^{L} \alpha_i H_{\text{BiGRU}}[i]
   $$

   其中，$ V \in \mathbb{R}^{2h} $ 是自注意力加权后的特征向量，包含了RNA序列的全局特征信息，聚焦于RBP可能结合的重要位点。

---

### 3. 全连接层与输出

BiGRU和自注意力机制生成的全局上下文向量 $ V $ 被输入到全连接层，经过一系列线性变换后进入Softmax分类器，以输出预测结果。最终的输出是一个二分类概率分布，用于区分RBP结合位点（正样本）和非结合位点（负样本）。

- **Softmax分类器**：

$$
\hat{y} = \text{Softmax}(W_o V + b_o)
$$

其中：
- $ W_o $ 和 $ b_o $ 是全连接层的权重和偏置。
- $ \hat{y} $ 是模型的预测概率向量，表示输入序列为RBP结合位点或非结合位点的概率。

---

### 总结

- **DMSRN**模块通过多尺度卷积和残差连接，提取了RNA序列的局部上下文信息。
- **BiGRU**模块在DMSRN的基础上进一步捕捉长程依赖特征。
- **自注意力机制**对BiGRU输出进行加权，使模型更加关注关键位点，生成包含全局上下文信息的特征向量。
- 最后，通过全连接层和Softmax分类器对每个输入序列进行二分类预测。

这一架构使得iCircRBP-DHN能够准确捕捉circRNA序列中的局部和全局特征，并识别与RBP结合相关的重要位点。

# 数据在从raw data 部分到输入到模型，到模型中的各个阶段，到输出，整个数据流在模型中的shape 是如何变化的

以下是iCircRBP-DHN模型中数据从原始输入数据（raw data）到输出的整个数据流过程，并详细说明了每个阶段数据的shape变化：

---

### 1. 原始数据输入（Raw Data）
- **原始序列输入**：每个circRNA片段的长度为101个核苷酸。
- **初始数据表示**：每个核苷酸（A、C、G、U）使用one-hot编码为4维向量。
- **输入数据shape**：对于每个circRNA片段，初始输入的shape为：
  $$
  (101, 4)
  $$

### 2. 数据预处理和特征提取

#### 2.1 K-元核苷酸频率模式（KNFP）
- **特征生成**：KNFP模块生成单核苷酸（K=1）、二核苷酸（K=2）和三核苷酸（K=3）的频率特征。
- **特征维度**：
  - K=1时：4种单核苷酸（A、C、G、U），特征向量为4维。
  - K=2时：16种二核苷酸组合，特征向量为16维。
  - K=3时：64种三核苷酸组合，特征向量为64维。
- **总特征维度**：4 + 16 + 64 = 84维。
- **输出shape**：KNFP生成的特征向量shape为：
  $$
  (84,)
  $$

#### 2.2 CircRNA2Vec
- **特征生成**：CircRNA2Vec将101个核苷酸长度的序列切分为多个10个核苷酸长度的重叠子序列，每个子序列间隔步长为1。生成的子序列通过Word2Vec嵌入生成向量表示。
- **生成子序列数量**：若子序列长度为10，步长为1，则生成 $ 101 - 10 + 1 = 92 $ 个子序列。
- **嵌入维度**：假设Word2Vec生成的每个子序列嵌入向量为100维。
- **输出shape**：CircRNA2Vec生成的特征矩阵shape为：
  $$
  (92, 100)
  $$

### 3. 数据输入到模型

将KNFP和CircRNA2Vec的特征进行拼接，形成模型的初始输入特征矩阵：

$$
\text{输入特征} = \begin{bmatrix} \text{KNFP特征向量} \\ \text{CircRNA2Vec特征矩阵} \end{bmatrix}
$$

假设将KNFP特征复制到CircRNA2Vec的每个子序列维度，以保持维度一致性，则输入到模型的特征shape为：

$$
(92, 100 + 84) = (92, 184)
$$

---

### 4. 深度多尺度残差网络（DMSRN）

#### 4.1 多尺度卷积层
- **卷积操作**：DMSRN中使用不同窗口大小的卷积核（如1、3、5）提取多尺度特征。
- **假设卷积核数量**：假设每个尺度的卷积核数量为64。
- **输出shape**：每种卷积核生成的特征矩阵shape为：
  $$
  (92, 64)
  $$
- **多尺度拼接**：拼接所有尺度的特征后，DMSRN的输出shape为：
  $$
  (92, 64 \times 3) = (92, 192)
  $$

#### 4.2 残差连接
- **残差加和**：将输入矩阵（shape为$ (92, 184) $）与多尺度卷积拼接结果（shape为$ (92, 192) $）相加。
- **输出shape**：DMSRN的最终输出shape为：
  $$
  (92, 192)
  $$

---

### 5. 双向门控循环单元网络（BiGRU）

- **输入**：DMSRN的输出（shape为$ (92, 192) $）传递给BiGRU层。
- **BiGRU单向隐藏单元数量**：假设单向GRU隐藏单元数量为128。
- **输出shape**：双向BiGRU的输出为：
  $$
  (92, 128 \times 2) = (92, 256)
  $$

---

### 6. 自注意力机制

#### 6.1 注意力得分计算
- **计算注意力得分**：对BiGRU的输出矩阵$ H_{\text{BiGRU}} \in \mathbb{R}^{92 \times 256} $ 进行注意力加权。
- **注意力得分shape**：注意力权重矩阵 $ \alpha \in \mathbb{R}^{92 \times 1} $。

#### 6.2 加权求和
- **生成全局特征向量**：对BiGRU输出按注意力权重加权求和，生成全局特征向量 $ V $。
- **输出shape**：全局特征向量 $ V $ 的shape为：
  $$
  (256,)
  $$

---

### 7. 全连接层与输出

- **输入**：自注意力机制输出的全局特征向量 $ V $。
- **全连接层**：通过全连接层和softmax分类器生成二分类概率。
- **输出shape**：最终输出为2维概率向量，表示RBP结合位点和非结合位点的概率：
  $$
  (2,)
  $$

---

### 总结

整个数据流中各阶段shape的变化如下：

1. **Raw Data**：$ (101, 4) $
2. **KNFP**：$ (84,) $
3. **CircRNA2Vec**：$ (92, 100) $
4. **拼接输入特征**：$ (92, 184) $
5. **DMSRN输出**：$ (92, 192) $
6. **BiGRU输出**：$ (92, 256) $
7. **自注意力输出**：$ (256,) $
8. **全连接层输出**：$ (2,) $

该流程表明，iCircRBP-DHN模型通过逐步提取和整合局部及全局特征，实现了高维特征向量到二分类概率的转化。